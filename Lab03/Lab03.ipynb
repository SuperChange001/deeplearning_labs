{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcFhSB8lde8B"
      },
      "source": [
        "# Lab 03: Embedded Deep Learning\n",
        "\n",
        "In this lab session, we will optimize the deep learning model that was trained in the last session. Later we will put the quantized model to the ESP32 MCU.\n",
        "\n",
        "Open in google colab -> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg#left)](https://colab.research.google.com/github/SuperChange001/deeplearning_labs/blob/main/Lab03/Lab03.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EV4SBCecxWZ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP98q8pBb0vc"
      },
      "source": [
        "First, we import some libraries for image processing and utils, as well as TensorFlow. Note that the module `image_dataset_from_directory` is necessary for downloading our data set from Google."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vpyxHufwFKYp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# Set the seed value for experiment reproducibility.\n",
        "seed = 32\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPfEkbUYG_ci"
      },
      "source": [
        "## Import the Gesture dataset for evaluating the pretrianed model\n",
        "\n",
        "Download and extract the `zip` file containing the datasets with `tf.keras.utils.get_file`. \n",
        "\n",
        "*Tips: change the code respectively if you have a model for other task.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy8hBBOCMlA0",
        "outputId": "279b61ca-4572-4c72-cb3c-0234ab03021d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip\n",
            "200687616/200682221 [==============================] - 9s 0us/step\n",
            "200695808/200682221 [==============================] - 9s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip\n",
            "29523968/29516758 [==============================] - 2s 0us/step\n",
            "29532160/29516758 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Download our dataset used for training\n",
        "TRAIN_SET_URL = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('rps.zip', origin=TRAIN_SET_URL, extract=True, cache_dir='/content')\n",
        "train_dir = os.path.join(os.path.dirname(path_to_zip), \"rps\")\n",
        "\n",
        "# As well as the validation dataset\n",
        "VAL_SET_URL = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip'\n",
        "path_to_zip2 = tf.keras.utils.get_file('rps-test-set.zip', origin=VAL_SET_URL, extract=True, cache_dir='/content')\n",
        "validation_dir = os.path.join(os.path.dirname(path_to_zip2), \"rps-test-set\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HBernrNHwFc"
      },
      "source": [
        "Then we can generate tf.data.Dataset from image files in a directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0HnHBGmNLh5",
        "outputId": "eeccc144-0565-4f04-d854-5817841e7830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2520 files belonging to 3 classes.\n",
            "Found 372 files belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (96, 96) \n",
        "\n",
        "train_dataset = image_dataset_from_directory(train_dir,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(validation_dir,\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  image_size=IMG_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRHrIWLUJDQR"
      },
      "source": [
        "Lets display some images of our dataset, as well as the class names."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGJ5uDKeJuvN"
      },
      "source": [
        "### Split test set and validation set\n",
        "We are now taking a fifth of the validation dataset to use as our test set. The validation set will be used for observing if we got overfitting during training while the test set is for the final test after training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkbBixY8NVbP",
        "outputId": "98425f91-9147-4004-fbea-4099c9602507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of validation batches: 10\n",
            "Number of test batches: 2\n"
          ]
        }
      ],
      "source": [
        "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
        "\n",
        "test_dataset = validation_dataset.take(val_batches // 5)\n",
        "validation_dataset = validation_dataset.skip(val_batches // 5)\n",
        "\n",
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSjEqLOIspiZ"
      },
      "source": [
        "## Upload model and load the model from hard disk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXUFpmD03n_v"
      },
      "source": [
        "Fetch the example model from github, you can also upload your own model to colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kY9rzyf5t1gj"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import h5py\n",
        "import requests\n",
        "\n",
        "url = 'https://github.com/SuperChange001/deeplearning_labs/raw/main/Lab03/pretrained_models/model_rps.h5'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "with open('/content/model_rps.h5', 'wb') as f:\n",
        "    f.write(r.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAA6tMyZ3n_w"
      },
      "source": [
        "Alternative way for fetching the pretrained model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP_iYinhrShE",
        "outputId": "1a22c0e9-8b80-4934-963d-66441d5606f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-15 14:20:28--  https://github.com/SuperChange001/deeplearning_labs/raw/main/Lab03/pretrained_models/model_rps.h5\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SuperChange001/deeplearning_labs/main/Lab03/pretrained_models/model_rps.h5 [following]\n",
            "--2022-08-15 14:20:28--  https://raw.githubusercontent.com/SuperChange001/deeplearning_labs/main/Lab03/pretrained_models/model_rps.h5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3441936 (3.3M) [application/octet-stream]\n",
            "Saving to: ‘model_rps.h5’\n",
            "\n",
            "model_rps.h5        100%[===================>]   3.28M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-08-15 14:20:28 (307 MB/s) - ‘model_rps.h5’ saved [3441936/3441936]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/SuperChange001/deeplearning_labs/raw/main/Lab03/pretrained_models/model_rps.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22HmS5zM3n_w"
      },
      "source": [
        "Load model from hard disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wzU3N-MsqeQ",
        "outputId": "9f65a9f3-15bd-49fb-8c81-39640c88d469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
            "                                                                 \n",
            " tf.math.truediv (TFOpLambda  (None, 96, 96, 3)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " tf.math.subtract (TFOpLambd  (None, 96, 96, 3)        0         \n",
            " a)                                                              \n",
            "                                                                 \n",
            " mobilenetv2_0.35_96 (Functi  (None, 3, 3, 1280)       410208    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1280)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 3843      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 414,051\n",
            "Trainable params: 337,699\n",
            "Non-trainable params: 76,352\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model('/content/model_rps.h5')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yeFoHyg3n_x"
      },
      "source": [
        "Test Accuracy of the loaded model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1OfCsJHwAx0",
        "outputId": "b5a182ea-7775-4c8d-e4ce-10f4752b712e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 12s 70ms/step - loss: 0.2492 - accuracy: 0.9219\n",
            "Test accuracy : 0.921875\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print('Test accuracy :', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFWEgNO83n_x"
      },
      "source": [
        "## Convert model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZbiMdnR03n_x"
      },
      "outputs": [],
      "source": [
        "# Parameters setting\n",
        "optimization_config = [tf.lite.Optimize.DEFAULT]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI6M0VxC3n_y"
      },
      "source": [
        "### Convert to a TensorFlow Lite model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJA1ep4S3n_y",
        "outputId": "6bfb4ea2-ca8b-476d-86cb-3ad6989d6e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "#TF Lite model without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJtFP0rd3n_y"
      },
      "source": [
        "### Convert using dynamic range quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlYVUayf3n_y",
        "outputId": "27206c49-4cf2-4372-d913-dfdfc386d8a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "#TF Lite model with dynamic range quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = optimization_config\n",
        "\n",
        "tflite_model_dynamic_range = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byb0_jnX3n_y"
      },
      "source": [
        "### Convert using float fallback quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHI_tjr93n_y",
        "outputId": "321f3ce2-b296-4c7c-df8f-149dd3ae4cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "#Extracts sample images needed for float fallback and full integer quantization \n",
        "def representative_data_gen():\n",
        "  for input in train_dataset.take(4):\n",
        "    for input_value in tf.data.Dataset.from_tensor_slices(np.array(input[0])).batch(1).take(32):\n",
        "      yield [input_value]\n",
        "\n",
        "#TF Lite model with Float Fallback quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = optimization_config\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "tflite_model_float_fallback = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyCemb1F3n_z"
      },
      "source": [
        "### Convert using integer-only quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H53110LWwOW4",
        "outputId": "f58d9f0b-5aa2-4480-8920-5edf3cac0a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "#TF Lite model with Full integer quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = optimization_config\n",
        "converter.representative_dataset = representative_data_gen\n",
        "# Ensure that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# Set the input and output tensors to int8 \n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "tflite_model_quant = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MizihKRI3n_z"
      },
      "source": [
        "### Save the models as files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffr_JCfE3n_z"
      },
      "source": [
        "You'll need a `.tflite` file to deploy your model on other devices. So let's save the converted models to files and then load them when we run inferences below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvJ__uWZwSFB",
        "outputId": "2bfb21b7-c43a-44e6-8f28-b8d39425b141"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "627696"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import pathlib\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"/content/rps_tflite_models/\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Save the unquantized/float model:\n",
        "\n",
        "tflite_model_file = tflite_models_dir/\"rps_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "\n",
        "# Save the dynamic range quantized model:\n",
        "\n",
        "tf_model_dynamic_range_file = tflite_models_dir/\"rps_model_dynamic_range.tflite\"\n",
        "tf_model_dynamic_range_file.write_bytes(tflite_model_dynamic_range)\n",
        "\n",
        "# Save the float fallback quantized model:\n",
        "\n",
        "tflite_model_float_fallback_file = tflite_models_dir/\"rps_model_float_fallback.tflite\"\n",
        "tflite_model_float_fallback_file.write_bytes(tflite_model_float_fallback)\n",
        "\n",
        "# Save the integer only quantized model:\n",
        "\n",
        "tflite_model_quant_file = tflite_models_dir/\"rps_model_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_model_quant)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the models"
      ],
      "metadata": {
        "id": "uSeUQzre54Iv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JWn82C2xwYUJ"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(tflite_file, dataset, model_type):\n",
        "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
        "\n",
        "  interpreter.allocate_tensors()\n",
        "  \n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  output_details =  interpreter.get_output_details()[0]\n",
        "\n",
        "  total_seen = 0\n",
        "  num_correct = 0\n",
        "  is_int8_quantized = (input_details['dtype'] == np.int8)\n",
        "  \n",
        "  for image_batch, labels_batch in dataset:\n",
        "    for i in range(tf.shape(image_batch)[0]):\n",
        "      test_image = image_batch[i]\n",
        "      \n",
        "\n",
        "      if is_int8_quantized:\n",
        "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "        test_image = test_image / input_scale + input_zero_point\n",
        "\n",
        "      test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
        "      interpreter.set_tensor(input_details[\"index\"], test_image)\n",
        "      interpreter.invoke()\n",
        "      output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "      output = np.argmax(output)\n",
        "\n",
        "      if labels_batch[i] == output:\n",
        "        num_correct += 1\n",
        "      total_seen += 1\n",
        "\n",
        "      if total_seen % 50 == 0:\n",
        "        print(\"Accuracy after %i images: %f\" %\n",
        "              (total_seen, float(num_correct) / float(total_seen)))\n",
        "  print('Num images: {0:}, Accuracy: {1:.4f}, Type: {2:}'.format(total_seen, float(num_correct / total_seen), model_type))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUrX2cX-wbIL",
        "outputId": "c5174038-a4f8-40a5-c7c2-edf9f6c88326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after 50 images: 0.800000\n",
            "Num images: 64, Accuracy: 0.7969, Type: Float\n",
            "Accuracy after 50 images: 0.920000\n",
            "Num images: 64, Accuracy: 0.9219, Type: Dynamic Range\n",
            "Accuracy after 50 images: 0.960000\n",
            "Num images: 64, Accuracy: 0.9688, Type: Float Fallback\n",
            "Accuracy after 50 images: 0.960000\n",
            "Num images: 64, Accuracy: 0.9531, Type: Integer Quantized\n",
            "2/2 [==============================] - 1s 67ms/step - loss: 0.2270 - accuracy: 0.9375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2269519865512848, 0.9375]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "#Check accuracy on the test subset\n",
        "evaluate_model(tflite_model_file, test_dataset, model_type=\"Float\")\n",
        "evaluate_model(tf_model_dynamic_range_file, test_dataset, model_type=\"Dynamic Range\")\n",
        "evaluate_model(tflite_model_float_fallback_file, test_dataset, model_type=\"Float Fallback\")\n",
        "evaluate_model(tflite_model_quant_file, test_dataset, model_type=\"Integer Quantized\")\n",
        "model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pH7j9yeweIW",
        "outputId": "b20a011b-2d7f-41ea-b0fe-f1d3b1b80346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after 50 images: 0.960000\n",
            "Accuracy after 100 images: 0.970000\n",
            "Accuracy after 150 images: 0.940000\n",
            "Accuracy after 200 images: 0.940000\n",
            "Accuracy after 250 images: 0.924000\n",
            "Accuracy after 300 images: 0.916667\n",
            "Num images: 308, Accuracy: 0.9188, Type: Float\n",
            "Accuracy after 50 images: 0.920000\n",
            "Accuracy after 100 images: 0.920000\n",
            "Accuracy after 150 images: 0.900000\n",
            "Accuracy after 200 images: 0.905000\n",
            "Accuracy after 250 images: 0.916000\n",
            "Accuracy after 300 images: 0.923333\n",
            "Num images: 308, Accuracy: 0.9253, Type: Dynamic Range\n",
            "Accuracy after 50 images: 0.960000\n",
            "Accuracy after 100 images: 0.960000\n",
            "Accuracy after 150 images: 0.960000\n",
            "Accuracy after 200 images: 0.970000\n",
            "Accuracy after 250 images: 0.972000\n",
            "Accuracy after 300 images: 0.963333\n",
            "Num images: 308, Accuracy: 0.9643, Type: Float Fallback\n",
            "Accuracy after 50 images: 0.940000\n",
            "Accuracy after 100 images: 0.960000\n",
            "Accuracy after 150 images: 0.966667\n",
            "Accuracy after 200 images: 0.965000\n",
            "Accuracy after 250 images: 0.964000\n",
            "Accuracy after 300 images: 0.966667\n",
            "Num images: 308, Accuracy: 0.9675, Type: Integer Quantized\n",
            "10/10 [==============================] - 1s 15ms/step - loss: 0.3054 - accuracy: 0.9156\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.30543866753578186, 0.9155844449996948]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "#Check accuracy on all validation data\n",
        "evaluate_model(tflite_model_file, validation_dataset, model_type=\"Float\")\n",
        "evaluate_model(tf_model_dynamic_range_file, validation_dataset, model_type=\"Dynamic Range\")\n",
        "evaluate_model(tflite_model_float_fallback_file, validation_dataset, model_type=\"Float Fallback\")\n",
        "evaluate_model(tflite_model_quant_file, validation_dataset, model_type=\"Integer Quantized\")\n",
        "model.evaluate(validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sc2VDnhwhxj",
        "outputId": "8429abd9-9752-4836-b157-f1aa256cb207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Float model in KB: 1573.6015625\n",
            "Dynamic Range model in KB: 592.25\n",
            "Float fallback model in KB: 613.3046875\n",
            "Integer Quantized model in KB: 612.984375\n"
          ]
        }
      ],
      "source": [
        "print(\"Float model in KB:\", os.path.getsize(tflite_model_file) / float(2**10))\n",
        "print(\"Dynamic Range model in KB:\", os.path.getsize(tf_model_dynamic_range_file) / float(2**10))\n",
        "print(\"Float fallback model in KB:\", os.path.getsize(tflite_model_float_fallback_file) / float(2**10))\n",
        "print(\"Integer Quantized model in KB:\", os.path.getsize(tflite_model_quant_file) / float(2**10))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So you now have an integer quantized a model with almost no difference in the accuracy, compared to the float model.\n",
        "\n",
        "To learn more about other quantization strategies, read about [TensorFlow Lite model optimization](https://www.tensorflow.org/lite/performance/model_optimization)."
      ],
      "metadata": {
        "id": "SJwR0DKO60sU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3B_DNmm3n_0"
      },
      "source": [
        "## Generate a TensorFlow Lite for MicroControllers Model\n",
        "Convert the TensorFlow Lite model into a C source file that can be loaded by TensorFlow Lite for Microcontrollers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPS179IlwUIY",
        "outputId": "a492985a-04df-408c-8caa-e66a293f23b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [90.7 kB]\n",
            "Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [903 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,937 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,310 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,095 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,533 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,100 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,369 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,141 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,073 kB]\n",
            "Get:24 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:25 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [47.7 kB]\n",
            "Fetched 17.0 MB in 7s (2,344 kB/s)\n",
            "Reading package lists... Done\n",
            "Selecting previously unselected package xxd.\n",
            "(Reading database ... 155680 files and directories currently installed.)\n",
            "Preparing to unpack .../xxd_2%3a8.0.1453-1ubuntu1.8_amd64.deb ...\n",
            "Unpacking xxd (2:8.0.1453-1ubuntu1.8) ...\n",
            "Setting up xxd (2:8.0.1453-1ubuntu1.8) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ],
      "source": [
        "# Install xxd if it is not available\n",
        "!apt-get update && apt-get -qq install xxd\n",
        "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
        "MODEL_TFLITE = \"/content/rps_tflite_models/rps_model_quant.tflite\"\n",
        "MODEL_TFLITE_MICRO = \"/content/rps_tflite_models/rps_model_quant.cc\"\n",
        "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
        "# Update variable names\n",
        "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
        "!sed -i 's/'{REPLACE_TEXT}'/rps_model_tflite/g' {MODEL_TFLITE_MICRO}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA2Md_eF3n_0"
      },
      "source": [
        "### Deploy to a Microcontroller\n",
        "We now need to move to PC side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NYd9vJ9-zHqm",
        "outputId": "fc4b7a94-65a7-4e0c-c5b7-9d2642ae57c1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_19b51a2b-fd30-4173-894a-e01df01ce5c2\", \"rps_model_quant.cc\", 3870875)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/rps_tflite_models/rps_model_quant.cc') "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Lab03.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}