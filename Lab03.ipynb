{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 03: Embedded AI\n",
        "\n",
        "In this lab session, we will optimize the deep learning model that was trained in the last session, so it can fit the embedded MCUs.\n"
      ],
      "metadata": {
        "id": "rcFhSB8lde8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "2EV4SBCecxWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we import some libraries for image processing and utils, as well as TensorFlow. Note that the module `image_dataset_from_directory` is necessary for downloading our data set from Google."
      ],
      "metadata": {
        "id": "eP98q8pBb0vc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vpyxHufwFKYp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# Set the seed value for experiment reproducibility.\n",
        "seed = 32\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the Gesture dataset for evaluating the model on our hard disk\n",
        "\n",
        "Download and extract the `zip` file containing the datasets with `tf.keras.utils.get_file`. \n",
        "\n",
        "*Tips: change the code respectively if you have a model for other task.*"
      ],
      "metadata": {
        "id": "ZPfEkbUYG_ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download our dataset used for training\n",
        "TRAIN_SET_URL = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('rps.zip', origin=TRAIN_SET_URL, extract=True, cache_dir='/content')\n",
        "train_dir = os.path.join(os.path.dirname(path_to_zip), \"rps\")\n",
        "\n",
        "# As well as the validation dataset\n",
        "VAL_SET_URL = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip'\n",
        "path_to_zip2 = tf.keras.utils.get_file('rps-test-set.zip', origin=VAL_SET_URL, extract=True, cache_dir='/content')\n",
        "validation_dir = os.path.join(os.path.dirname(path_to_zip2), \"rps-test-set\")"
      ],
      "metadata": {
        "id": "Oy8hBBOCMlA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02962262-ad98-4304-c11c-452639c2f12e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip\n",
            "200687616/200682221 [==============================] - 2s 0us/step\n",
            "200695808/200682221 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can generate tf.data.Dataset from image files in a directory.\n",
        "\n"
      ],
      "metadata": {
        "id": "0HBernrNHwFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (96, 96) \n",
        "\n",
        "train_dataset = image_dataset_from_directory(train_dir,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(validation_dir,\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  image_size=IMG_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0HnHBGmNLh5",
        "outputId": "b00f28de-8f91-4444-b532-2b4416f27c8b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2520 files belonging to 3 classes.\n",
            "Found 372 files belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets display some images of our dataset, as well as the class names."
      ],
      "metadata": {
        "id": "mRHrIWLUJDQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split test set and validation set\n",
        "We are now taking a fifth of the validation dataset to use as our test set. The validation set will be used for observing if we got overfitting during training while the test set is for the final test after training:"
      ],
      "metadata": {
        "id": "wGJ5uDKeJuvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
        "\n",
        "test_dataset = validation_dataset.take(val_batches // 5)\n",
        "validation_dataset = validation_dataset.skip(val_batches // 5)\n",
        "\n",
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
      ],
      "metadata": {
        "id": "kkbBixY8NVbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e97e4a-e88e-445a-8347-8bcd2667c434"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of validation batches: 10\n",
            "Number of test batches: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VSjEqLOIspiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import h5py\n",
        "import requests\n",
        "\n",
        "url = 'https://github.com/SuperChange001/deeplearning_labs/blob/main/model_rps.h5'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "# f= h5py.File('/content/model_rps.h5', 'w')\n",
        "# f.create_dataset(name =\"Test\", data = r.content)\n",
        "# f.close()\n",
        "\n",
        "with open('/content/model_rps.h5', 'wb') as f:\n",
        "    f.write(r.content)"
      ],
      "metadata": {
        "id": "kY9rzyf5t1gj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/SuperChange001/deeplearning_labs/raw/main/model_rps.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP_iYinhrShE",
        "outputId": "64cf56db-71a9-4a60-c9ba-ac7e1f9f3dcc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-12 15:50:01--  https://github.com/SuperChange001/deeplearning_labs/raw/main/model_rps.h5\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SuperChange001/deeplearning_labs/main/model_rps.h5 [following]\n",
            "--2022-08-12 15:50:01--  https://raw.githubusercontent.com/SuperChange001/deeplearning_labs/main/model_rps.h5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3441936 (3.3M) [application/octet-stream]\n",
            "Saving to: ‘model_rps.h5’\n",
            "\n",
            "\rmodel_rps.h5          0%[                    ]       0  --.-KB/s               \rmodel_rps.h5        100%[===================>]   3.28M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-08-12 15:50:01 (66.7 MB/s) - ‘model_rps.h5’ saved [3441936/3441936]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/model_rps.h5')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wzU3N-MsqeQ",
        "outputId": "63310679-2d63-4720-ed11-c217f5b3b02e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
            "                                                                 \n",
            " tf.math.truediv (TFOpLambda  (None, 96, 96, 3)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " tf.math.subtract (TFOpLambd  (None, 96, 96, 3)        0         \n",
            " a)                                                              \n",
            "                                                                 \n",
            " mobilenetv2_0.35_96 (Functi  (None, 3, 3, 1280)       410208    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1280)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 3843      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 414,051\n",
            "Trainable params: 337,699\n",
            "Non-trainable params: 76,352\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print('Test accuracy :', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1OfCsJHwAx0",
        "outputId": "9fe83b5b-a1c5-4823-80d7-9dfd4dc0e293"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 79ms/step - loss: 0.2895 - accuracy: 0.8906\n",
            "Test accuracy : 0.890625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TF Lite model without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "\n",
        "#TF Lite model with dynamic range quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_model_dynamic_range = converter.convert()\n",
        "\n",
        "\n",
        "#Extracts sample images needed for float fallback and full integer quantization \n",
        "def representative_data_gen():\n",
        "  for input in train_dataset.take(4):\n",
        "    for input_value in tf.data.Dataset.from_tensor_slices(np.array(input[0])).batch(1).take(32):\n",
        "      yield [input_value]\n",
        "\n",
        "\n",
        "#TF Lite model with Float Fallback quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "tflite_model_float_fallback = converter.convert()\n",
        "\n",
        "\n",
        "#TF Lite model with Full integer quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "# Ensure that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# Set the input and output tensors to int8 \n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "tflite_model_quant = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H53110LWwOW4",
        "outputId": "c6700139-2453-4f61-ab95-592e177a92b1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"/content/rps_tflite_models/\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Save the unquantized/float model:\n",
        "\n",
        "tflite_model_file = tflite_models_dir/\"rps_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "\n",
        "# Save the dynamic range quantized model:\n",
        "\n",
        "tf_model_dynamic_range_file = tflite_models_dir/\"rps_model_dynamic_range.tflite\"\n",
        "tf_model_dynamic_range_file.write_bytes(tflite_model_dynamic_range)\n",
        "\n",
        "# Save the float fallback quantized model:\n",
        "\n",
        "tflite_model_float_fallback_file = tflite_models_dir/\"rps_model_float_fallback.tflite\"\n",
        "tflite_model_float_fallback_file.write_bytes(tflite_model_float_fallback)\n",
        "\n",
        "# Save the integer only quantized model:\n",
        "\n",
        "tflite_model_quant_file = tflite_models_dir/\"rps_model_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_model_quant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvJ__uWZwSFB",
        "outputId": "ec924eb8-c7d7-4619-8f61-77954ce4a524"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "627696"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install xxd if it is not available\n",
        "!apt-get update && apt-get -qq install xxd\n",
        "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
        "MODEL_TFLITE = \"/content/rps_tflite_models/rps_model_quant.tflite\"\n",
        "MODEL_TFLITE_MICRO = \"/content/rps_tflite_models/rps_model_quant.cc\"\n",
        "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
        "# Update variable names\n",
        "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
        "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPS179IlwUIY",
        "outputId": "e468e7ac-461a-4cab-afc4-ede2dacbaadf"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 163 kB in 2s (93.0 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(tflite_file, dataset, model_type):\n",
        "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
        "\n",
        "  interpreter.allocate_tensors()\n",
        "  \n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  output_details =  interpreter.get_output_details()[0]\n",
        "\n",
        "  total_seen = 0\n",
        "  num_correct = 0\n",
        "  is_int8_quantized = (input_details['dtype'] == np.int8)\n",
        "  \n",
        "  for image_batch, labels_batch in dataset:\n",
        "    for i in range(tf.shape(image_batch)[0]):\n",
        "      test_image = image_batch[i]\n",
        "      \n",
        "\n",
        "      if is_int8_quantized:\n",
        "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "        test_image = test_image / input_scale + input_zero_point\n",
        "\n",
        "      test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
        "      interpreter.set_tensor(input_details[\"index\"], test_image)\n",
        "      interpreter.invoke()\n",
        "      output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "      output = np.argmax(output)\n",
        "\n",
        "      if labels_batch[i] == output:\n",
        "        num_correct += 1\n",
        "      total_seen += 1\n",
        "\n",
        "      if total_seen % 50 == 0:\n",
        "        print(\"Accuracy after %i images: %f\" %\n",
        "              (total_seen, float(num_correct) / float(total_seen)))\n",
        "  print('Num images: {0:}, Accuracy: {1:.4f}, Type: {2:}'.format(total_seen, float(num_correct / total_seen), model_type))"
      ],
      "metadata": {
        "id": "JWn82C2xwYUJ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check accuracy on the test subset\n",
        "\n",
        "evaluate_model(tflite_model_file, test_dataset, model_type=\"Float\")\n",
        "evaluate_model(tf_model_dynamic_range_file, test_dataset, model_type=\"Dynamic Range\")\n",
        "evaluate_model(tflite_model_float_fallback_file, test_dataset, model_type=\"Float Fallback\")\n",
        "evaluate_model(tflite_model_quant_file, test_dataset, model_type=\"Integer Quantized\")\n",
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUrX2cX-wbIL",
        "outputId": "be7a1cf3-bd10-40f4-c3cd-b872e7d96183"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after 50 images: 0.920000\n",
            "Num images: 64, Accuracy: 0.9219, Type: Float\n",
            "Accuracy after 50 images: 0.940000\n",
            "Num images: 64, Accuracy: 0.9531, Type: Dynamic Range\n",
            "Accuracy after 50 images: 1.000000\n",
            "Num images: 64, Accuracy: 1.0000, Type: Float Fallback\n",
            "Accuracy after 50 images: 1.000000\n",
            "Num images: 64, Accuracy: 0.9844, Type: Integer Quantized\n",
            "2/2 [==============================] - 1s 71ms/step - loss: 0.3871 - accuracy: 0.8906\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3871323764324188, 0.890625]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check accuracy on all validation data\n",
        "\n",
        "evaluate_model(tflite_model_file, validation_dataset, model_type=\"Float\")\n",
        "evaluate_model(tf_model_dynamic_range_file, validation_dataset, model_type=\"Dynamic Range\")\n",
        "evaluate_model(tflite_model_float_fallback_file, validation_dataset, model_type=\"Float Fallback\")\n",
        "evaluate_model(tflite_model_quant_file, validation_dataset, model_type=\"Integer Quantized\")\n",
        "model.evaluate(validation_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pH7j9yeweIW",
        "outputId": "18395a1d-f5ad-4a08-c757-ff161c547a01"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after 50 images: 0.880000\n",
            "Accuracy after 100 images: 0.940000\n",
            "Accuracy after 150 images: 0.920000\n",
            "Accuracy after 200 images: 0.930000\n",
            "Accuracy after 250 images: 0.924000\n",
            "Accuracy after 300 images: 0.913333\n",
            "Num images: 308, Accuracy: 0.9156, Type: Float\n",
            "Accuracy after 50 images: 0.960000\n",
            "Accuracy after 100 images: 0.950000\n",
            "Accuracy after 150 images: 0.966667\n",
            "Accuracy after 200 images: 0.935000\n",
            "Accuracy after 250 images: 0.936000\n",
            "Accuracy after 300 images: 0.930000\n",
            "Num images: 308, Accuracy: 0.9286, Type: Dynamic Range\n",
            "Accuracy after 50 images: 0.980000\n",
            "Accuracy after 100 images: 0.980000\n",
            "Accuracy after 150 images: 0.980000\n",
            "Accuracy after 200 images: 0.970000\n",
            "Accuracy after 250 images: 0.972000\n",
            "Accuracy after 300 images: 0.966667\n",
            "Num images: 308, Accuracy: 0.9675, Type: Float Fallback\n",
            "Accuracy after 50 images: 0.980000\n",
            "Accuracy after 100 images: 0.990000\n",
            "Accuracy after 150 images: 0.993333\n",
            "Accuracy after 200 images: 0.980000\n",
            "Accuracy after 250 images: 0.972000\n",
            "Accuracy after 300 images: 0.966667\n",
            "Num images: 308, Accuracy: 0.9675, Type: Integer Quantized\n",
            "10/10 [==============================] - 1s 15ms/step - loss: 0.3290 - accuracy: 0.9091\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3289748728275299, 0.9090909361839294]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Float model in KB:\", os.path.getsize(tflite_model_file) / float(2**10))\n",
        "print(\"Dynamic Range model in KB:\", os.path.getsize(tf_model_dynamic_range_file) / float(2**10))\n",
        "print(\"Float fallback model in KB:\", os.path.getsize(tflite_model_float_fallback_file) / float(2**10))\n",
        "print(\"Integer Quantized model in KB:\", os.path.getsize(tflite_model_quant_file) / float(2**10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sc2VDnhwhxj",
        "outputId": "984c4c22-541f-4b9a-8d19-83d700323c61"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Float model in KB: 1573.6015625\n",
            "Dynamic Range model in KB: 592.25\n",
            "Float fallback model in KB: 613.3046875\n",
            "Integer Quantized model in KB: 612.984375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/rps_tflite_models/rps_model_quant.cc') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NYd9vJ9-zHqm",
        "outputId": "b0989ea4-b325-4670-f04f-34b97dfd466b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a4d0cd74-82b5-4199-b42e-b9ffd44322ea\", \"rps_model_quant.cc\", 3870857)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}